# @package experiment
name: "bert_gat"
system: CandidateFreeTE
trainer_args:
  gpus: 1
  max_epochs: 25
  gradient_clip_val: 1.0
  check_val_every_n_epoch: 5
dataset:
  _target_: data.TaxoBERTDataModule
  tokenizer:
    _target_: models.BertFastTokenizer
  data_root: ${experiment.data_root}
  batch_size: 32
net:
  _target_: models.KBertGATEnricher
  base_model: 'bert-base-uncased'
  gat_n_heads: 4
  gat_hidden_size: 32
  bert_encoder: True
  freeze_embedding: True
optimizer:
  _target_: torch.optim.Adam
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  epochs: 100
  steps_per_epoch: ${experiment.trainer_args.max_epochs}
  max_lr: 0.001
  pct_start: 0.2
